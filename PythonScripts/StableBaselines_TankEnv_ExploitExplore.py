import os
import argparse
import time
from config_gen import config_gen
import json
from elo import elo_prob
from random import shuffle, randint, choice, uniform
from stable_baselines3 import SAC

ID = 0
ELO = 1
    
# Setup command line arguments
parser = argparse.ArgumentParser()
parser.add_argument("game_path", type=str, help="File path of game executable")
parser.add_argument("game_config_file_path", type=str, help="File path of game config file")
parser.add_argument("eval_script", type=str, help="Evaluation script path")
parser.add_argument("model_dir", type=str, help="Base directory for agent models")
parser.add_argument("pop_file_path", type=str, help="Path to file that contains IDs of agents in population to train")
parser.add_argument("noun_file_path", type=str, help="Path to noun file used to generate names")
parser.add_argument("adj_file_path", type=str, help="Path to adj file used to generate names")
parser.add_argument("--win_thresh", type=float, default=.7, help = "Threshold value for win rate that determines when superior models replace inferior ones")
parser.add_argument("--num_trials", type=int, default=50, help="Number of trials for each pair in population to play out when evaluating for replacement")
parser.add_argument("--gamelog", type=str, default="gamelog.txt", help="Log file to direct game logging to")
args = parser.parse_args()
print(args)

def get_reward_clear_stats(agent_id):
    agent_stats_file_path = args.model_dir + remove_steps(agent_id) + "/stats.json"
    with open(agent_stats_file_path, 'r') as agent_stats_file:
        agent_stats = json.load(agent_stats_file)
    last_reward = agent_stats["performance"]["avg_reward"][-1]
    agent_stats["performance"]["avg_reward"] = agent_stats["performance"]["avg_reward"][:-1]
    agent_stats["performance"]["avg_steps"] = agent_stats["performance"]["avg_steps"][:-1]
    agent_stats["performance"]["trained_steps"] = agent_stats["performance"]["trained_steps"][:-1]
    with open(agent_stats_file_path, 'w') as agent_stats_file:
        json.dump(agent_stats, agent_stats_file, indent=4)
    return (last_reward + 1.) / 2.
    
def remove_steps(id):
    return "".join(id.split('_')[:-1])

def evaluate(agent_a, agent_b):
    # Establish opponents file so agent_a plays against agent_b
    with open(args.model_dir + remove_steps(agent_a[ID]) + "/opponents.txt", 'w') as opp_file:
        opp_file.write(agent_b[ID])
    # Setup game for evaluation
    config_gen(args.game_config_file_path, random_start=False)
    os.system(args.game_path + " > " + args.gamelog + " &")
    # Execute evaluation script
    os.system("python " + args.eval_script + " " + args.model_dir + " " + remove_steps(agent_a[ID]) + " --num_trials " + str(args.num_trials))
    return get_reward_clear_stats(agent_a[ID])
    
def gen_name():
    with open(args.noun_file_path, 'r') as noun_file, open(args.adj_file_path, 'r') as adj_file:
        while True:
            name = choice(adj_file.readlines()).strip('\n').capitalize()+\
                choice(noun_file.readlines()).strip('\n').capitalize()+str(randint(0,100))
            if not os.path.isdir(args.model_dir + name):
                return name
                
def new_agent(source_agent):
    print("SOURCE AGENT", source_agent)
    name = gen_name()
    print("NAME", name)
    src_model_file_path = args.model_dir + remove_steps(source_agent[ID]) + "/" + source_agent[ID]
    print(src_model_file_path)
    model = SAC.load(src_model_file_path)
    # Exploration - for now just altering learning rate randomly
    new_lr = float(max(0., model.learning_rate+(model.learning_rate*uniform(-.1, .1))))
    model = SAC.load(src_model_file_path, learning_rate=new_lr)
    # End Exploration
    new_model_file_path = args.model_dir + name + "/" + name + "_0"
    model.save(new_model_file_path)
    new_model_stats = {"num_steps":0,
                        "performance":{ "avg_reward":[],
                                        "avg_steps":[],
                                        "trained_steps":[]
                                    },
                        "elo":{ "value":[source_agent[ELO]],
                                "steps":[0]
                            },
                        "parent":source_agent[ID]
                    }
    with open(args.model_dir + name + "/stats.json", 'w') as new_model_stats_file:
        json.dump(new_model_stats, new_model_stats_file, indent=4)
    return name
    
    
if not (args.model_dir[-1] == '/' or args.model_dir[-1] == '\\'):
    args.model_dir = args.model_dir + "/"
    
if not os.path.exists(args.game_path):
    raise FileNotFoundError("Inputted game path does not lead to an existing file")
    
if not os.path.exists(args.game_config_file_path):
    raise FileNotFoundError("Game config file not found")
    
if not os.path.exists(args.eval_script):
    raise FileNotFoundError("Python Evaluation script not found")
    
if not os.path.isdir(args.model_dir):
    raise FileNotFoundError("Base directory for agent models is not a folder")
    
if not os.path.exists(args.pop_file_path):
    raise FileNotFoundError("Inputted path does not lead to population file")
    
population = []
with open(args.pop_file_path, 'r') as pop_file:
    for line in pop_file.readlines():
        population.append(line.strip('\n'))
        
pop_elos = []
for i,p in enumerate(population):
    if not os.path.isdir(args.model_dir + p):
        raise FileNotFoundError("Agent ID {" + p + "} does not lead to a valid model directory")
    p_stats_path = args.model_dir + p + "/stats.json"
    if not os.path.exists(p_stats_path):
        raise FileNotFoundError("Agent ID (" + p + ") does not have a stats file")
    with open(p_stats_path, 'r') as p_stats_file:
        p_stats = json.load(p_stats_file)
    p_step = p_stats["num_steps"]
    p_elo = p_stats["elo"]["value"][-1]
    if not os.path.exists(args.model_dir + p + "/" + p + "_" + str(p_step) + ".zip"):
        raise FileNotFoundError("Agent ID (" + p + ") does not have a correct saved policy file")
    population[i] += "_" + str(p_step)
    pop_elos.append(p_elo)
      
pop_with_elos = [x for x in zip(population, pop_elos)]
print("Current population:", pop_with_elos)
pairs = [(a,b) for idx,a in enumerate(pop_with_elos) for b in pop_with_elos[idx+1:]]
shuffle(pairs)
print("Order of evaluation:")
for p in pairs:
    print('\t' + str(p))
    
replaced = []
for (agent_a, agent_b) in pairs:
    if agent_a[ID] in replaced or agent_b[ID] in replaced:
        continue
    win_prob = elo_prob(agent_a[ELO], agent_b[ELO])
    if win_prob < 1-args.win_thresh:
        tmp = agent_a
        agent_a = agent_b
        agent_b = tmp
        win_prob = 1 - win_prob
    if win_prob > args.win_thresh:
        print("Evaluating", agent_a[ID], "vs", agent_b[ID], "for replacement")
        agent_a_win_rate = (evaluate(agent_a, agent_b) + (1-evaluate(agent_b, agent_a)))/2.
        if agent_a_win_rate > .7:
            print("Replacing", agent_b[ID], "with", agent_a[ID], "due to win rate", agent_a_win_rate)
            name = new_agent(agent_a)
            print("\t--New name:", name)
            replaced.append(agent_b[ID])
            population.remove(agent_b[ID])
            population.append(name + "_0")
        else:
            print(agent_a[ID], "was not able to beat", agent_b[ID], "with a win rate above threshold", args.win_thresh)
            print("\t--Evaluated win rate:", agent_a_win_rate)
if len(replaced):
    print("New Population:", population)
else:
    print("No replacements in population")
with open(args.pop_file_path, 'w') as pop_file:
    for p in population:
        pop_file.write(remove_steps(p) + '\n')
'''
for p,p_elo in zip(population, pop_elos):
    id = "".join(p.split('_')[:-1])
    # Setup game for training
    config_gen(args.game_config_file_path, random_start=args.rs)
    os.system(args.game_path + " > " + args.gamelog + " &")
    # Establish opponents for model to play against
    opp_file_path = args.model_dir + id + "/opponents.txt"
    with open(opp_file_path, 'w') as opp_file:
        for opp,opp_elo in zip(population, pop_elos):
            if p == opp:
                continue
            opp_file.write(opp + "\t" + str(opp_elo) + "\n")
    # Execute training script
    os.system("python " + args.training_script + " " + args.model_dir + " " + id + " --steps " + str(args.steps) + " --elo " + str(p_elo))
    
print("Training complete")
'''