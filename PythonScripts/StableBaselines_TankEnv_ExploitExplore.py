import os
os.environ['MKL_THREADING_LAYER'] = 'GNU'
import argparse
from config_gen import config_gen
import json
from elo import elo_prob
from random import shuffle, randint, choice, uniform
from stable_baselines3 import PPO
import subprocess

ID = 0
ELO = 1
    
# Setup command line arguments
parser = argparse.ArgumentParser()
parser.add_argument("game_path", type=str, help="File path of game executable")
parser.add_argument("game_config_file_path", type=str, help="File path of game config file")
parser.add_argument("eval_script", type=str, help="Evaluation script path")
parser.add_argument("model_dir", type=str, help="Base directory for agent models")
parser.add_argument("pop_file_path", type=str, help="Path to file that contains IDs of agents in population to train")
parser.add_argument("noun_file_path", type=str, help="Path to noun file used to generate names")
parser.add_argument("adj_file_path", type=str, help="Path to adj file used to generate names")
parser.add_argument("--win_thresh", type=float, default=.7, help = "Threshold value for win rate that determines when superior models replace inferior ones")
parser.add_argument("--num_trials", type=int, default=50, help="Number of trials for each pair in population to play out when evaluating for replacement")
parser.add_argument("--min_step", type=int, default=1000000, help="Minimum number of steps before agents can be considered for replacement")
parser.add_argument("--gamelog", type=str, default="gamelog.txt", help="Log file to direct game logging to")
args = parser.parse_args()
print(args)

def get_reward_clear_stats(agent_id):
    agent_stats_file_path = args.model_dir + remove_steps(agent_id) + "/stats.json"
    with open(agent_stats_file_path, 'r') as agent_stats_file:
        agent_stats = json.load(agent_stats_file)
    last_reward = agent_stats["performance"]["avg_reward"][-1]
    agent_stats["performance"]["avg_reward"] = agent_stats["performance"]["avg_reward"][:-1]
    agent_stats["performance"]["avg_steps"] = agent_stats["performance"]["avg_steps"][:-1]
    agent_stats["performance"]["trained_steps"] = agent_stats["performance"]["trained_steps"][:-1]
    with open(agent_stats_file_path, 'w') as agent_stats_file:
        json.dump(agent_stats, agent_stats_file, indent=4)
    return (last_reward + 1.) / 2.
    
def remove_steps(id):
    return "".join(id.split('_')[:-1])

def evaluate(agent_a, agent_b):
    # Establish opponents file so agent_a plays against agent_b
    with open(args.model_dir + remove_steps(agent_a[ID]) + "/opponents.txt", 'w') as opp_file:
        opp_file.write(agent_b[ID])
    # Setup game for evaluation
    config_gen(args.game_config_file_path, random_start=False)
    # Loop forever so that if system fails, that error will keep repeating (for debugging purposes)
    # If that error only happens occasionaly, then this loop will be broken
    while True:
        # Run game
        with open(os.path.expanduser(args.gamelog), 'w') as gl:
            game_p = subprocess.Popen(args.game_path, stdout=gl, stderr=gl)
            # Execute evaluation script
            cmd_list = ["python", args.eval_script,
                        args.model_dir, remove_steps(agent_a[ID]),
                        "--num_trials", str(args.num_trials)]
            with open(os.path.expanduser(args.model_dir + agent_a[ID].split('_')[0] + "/replace_log.txt"), 'a') as rl:
                print("Starting EE evalulation of " + agent_a[ID] + " vs " + agent_b[ID] + "\n")
                eval_p = subprocess.Popen(cmd_list, stdout=rl, stderr=rl)
                eval_return = eval_p.wait()
                print("Ending EE evaluation with exit code: " + str(eval_return) + "\n")
            game_p.kill()
        if eval_return in [0, -6, -7, -11]:
            break
        else:
            print("Had an exit code of", eval_return, "so redoing EE of", agent_a[ID] + " vs " + agent_b[ID])
    return get_reward_clear_stats(agent_a[ID])
    
def gen_name():
    with open(args.noun_file_path, 'r') as noun_file, open(args.adj_file_path, 'r') as adj_file:
        while True:
            name = choice(adj_file.readlines()).strip('\n').capitalize()+\
                choice(noun_file.readlines()).strip('\n').capitalize()+str(randint(0,100))
            if not os.path.isdir(args.model_dir + name):
                return name
                
def child_agent(source_agent):
    print("SOURCE AGENT", source_agent)
    name = gen_name()
    print("NAME", name)
    src_model_file_path = args.model_dir + remove_steps(source_agent[ID]) + "/" + source_agent[ID]
    print(src_model_file_path)
    model = PPO.load(src_model_file_path)
    # Exploration - for now just altering learning rate randomly
    new_lr = float(min(1., max(0., model.learning_rate+(model.learning_rate*uniform(-.1, .1)))))
    new_n_steps = int(max(0., model.n_steps+(model.n_steps*uniform(-.1, .1))))
    new_batch_size = int(max(0., model.batch_size+(model.batch_size*uniform(-.1, .1))))
    new_gamma = float(min(max(0.,model.gamma+(model.gamma*uniform(-.001, .001))), .99999999))
    model = PPO.load(src_model_file_path, learning_rate=new_lr, 
                                            n_steps=new_n_steps,
                                            batch_size=new_batch_size,
                                            gamma=new_gamma)
    # End Exploration
    new_model_file_path = args.model_dir + name + "/" + name + "_0"
    model.save(new_model_file_path)
    new_model_stats = {"num_steps":0,
                        "performance":{ "avg_reward":[],
                                        "avg_steps":[],
                                        "trained_steps":[]
                                    },
                        "elo":{ "value":[source_agent[ELO]],
                                "steps":[0]
                            },
                        "parent":source_agent[ID]
                    }
    with open(args.model_dir + name + "/stats.json", 'w') as new_model_stats_file:
        json.dump(new_model_stats, new_model_stats_file, indent=4)
    return name
    
    
if not (args.model_dir[-1] == '/' or args.model_dir[-1] == '\\'):
    args.model_dir = args.model_dir + "/"
    
if not os.path.exists(args.game_path):
    raise FileNotFoundError("Inputted game path does not lead to an existing file")
    
if not os.path.exists(args.game_config_file_path):
    raise FileNotFoundError("Game config file not found")
    
if not os.path.exists(args.eval_script):
    raise FileNotFoundError("Python Evaluation script not found")
    
if not os.path.isdir(args.model_dir):
    raise FileNotFoundError("Base directory for agent models is not a folder")
    
if not os.path.exists(args.pop_file_path):
    raise FileNotFoundError("Inputted path does not lead to population file")
    
if not os.path.exists(args.noun_file_path):
    raise FileNotFoundError("Inputted path does not lead to noun file")
    
if not os.path.exists(args.adj_file_path):
    raise FileNotFoundError("Inputted path does not lead to adjective file")
    
population = []
with open(args.pop_file_path, 'r') as pop_file:
    for line in pop_file.readlines():
        population.append(line.strip('\n'))
        
pop_elos = []
for i,p in enumerate(population):
    if not os.path.isdir(args.model_dir + p):
        raise FileNotFoundError("Agent ID {" + p + "} does not lead to a valid model directory")
    p_stats_path = args.model_dir + p + "/stats.json"
    if not os.path.exists(p_stats_path):
        raise FileNotFoundError("Agent ID (" + p + ") does not have a stats file")
    with open(p_stats_path, 'r') as p_stats_file:
        p_stats = json.load(p_stats_file)
    p_step = p_stats["num_steps"]
    p_elo = p_stats["elo"]["value"][-1]
    if not os.path.exists(args.model_dir + p + "/" + p + "_" + str(p_step) + ".zip"):
        raise FileNotFoundError("Agent ID (" + p + ") does not have a correct saved policy file")
    population[i] += "_" + str(p_step)
    pop_elos.append(p_elo)
      
pop_with_elos = [x for x in zip(population, pop_elos)]
print("Current population:", pop_with_elos)
pairs = [(a,b) for idx,a in enumerate(pop_with_elos) for b in pop_with_elos[idx+1:]]
shuffle(pairs)
print("Order of evaluation:")
for p in pairs:
    print('\t' + str(p))
    
replaced = []
for (agent_a, agent_b) in pairs:
    print(agent_a, "compared to", agent_b)
    # If one agent has already been replaced, skip
    if agent_a[ID] in replaced or agent_b[ID] in replaced:
        print(agent_a[ID] if agent_a[ID] in replaced else agent_b, "has already been replaced")
        continue
    # If one agent has not met the minimum step requirement, skip
    if int(agent_a[ID].split('_')[-1]) < args.min_step or int(agent_b[ID].split('_')[-1]) < args.min_step:
        print(agent_a[ID] if int(agent_a[ID].split('_')[-1]) < args.min_step else agent_b[ID], "does not have the minimum number of steps")
        continue
    # Calculate win probability of agent_a vs agent_b
    win_prob = elo_prob(agent_a[ELO], agent_b[ELO])
    # Agent_a should be the agent that should win, should either agent have a chance of replacing the other
    if win_prob < 1-args.win_thresh:
        tmp = agent_a
        agent_a = agent_b
        agent_b = tmp
        win_prob = 1 - win_prob
    # Evaluate agent_a vs agent_b if agent_a is expected to win over a threshold probability
    if win_prob > args.win_thresh:
        print("Evaluating", agent_a[ID], "vs", agent_b[ID], "for replacement")
        agent_a_win_rate = (evaluate(agent_a, agent_b) + (1-evaluate(agent_b, agent_a)))/2.
        if agent_a_win_rate > .7:
            print("Replacing", agent_b[ID], "with", agent_a[ID], "due to win rate", agent_a_win_rate)
            name = child_agent(agent_a)
            print("\t--New name:", name)
            replaced.append(agent_b[ID])
            population.remove(agent_b[ID])
            population.append(name + "_0")
        else:
            print(agent_a[ID], "was not able to beat", agent_b[ID], "with a win rate above threshold", args.win_thresh)
            print("\t--Evaluated win rate:", agent_a_win_rate)
    else:
        print("Win prob of", win_prob, "is not enough to evaluate", agent_a[ID], "against", agent_b[ID])
if len(replaced):
    print("New Population:", population)
else:
    print("No replacements in population")
with open(args.pop_file_path, 'w') as pop_file:
    for p in population:
        pop_file.write(remove_steps(p) + '\n')